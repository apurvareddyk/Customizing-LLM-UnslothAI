{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0730446755d426399ac87367877d8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3f3712618444f94855532d8bf182a69",
              "IPY_MODEL_aff9afd2db2d478699bf2e1951de358e",
              "IPY_MODEL_4956662318004b0c87a9526f87f5862f"
            ],
            "layout": "IPY_MODEL_f344befe08db49458d6cb11d02a33456"
          }
        },
        "c3f3712618444f94855532d8bf182a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcb704f7be7d4f3a9168bb6541676078",
            "placeholder": "​",
            "style": "IPY_MODEL_bf7ec76ce30449a8a61a462a18009239",
            "value": "Map: 100%"
          }
        },
        "aff9afd2db2d478699bf2e1951de358e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f5dedaa0e0b455483d2f074fb5ba6ef",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_640e99d4e4524d31a2379cb3c7aac9cf",
            "value": 1000
          }
        },
        "4956662318004b0c87a9526f87f5862f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e370b46e37344a6b677ef520c4c51d5",
            "placeholder": "​",
            "style": "IPY_MODEL_4887e47e9b1e49188ea09fd06033baa7",
            "value": " 1000/1000 [00:00&lt;00:00, 15262.50 examples/s]"
          }
        },
        "f344befe08db49458d6cb11d02a33456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb704f7be7d4f3a9168bb6541676078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7ec76ce30449a8a61a462a18009239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f5dedaa0e0b455483d2f074fb5ba6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640e99d4e4524d31a2379cb3c7aac9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e370b46e37344a6b677ef520c4c51d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4887e47e9b1e49188ea09fd06033baa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acd88f544d9841e791f788f4b0940c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1079c73096bf40f0846d369243632230",
              "IPY_MODEL_ed09bb176f9a4bb0a7164d1e74901ba9",
              "IPY_MODEL_3281b490b2f1461db00032c15f89f9fa"
            ],
            "layout": "IPY_MODEL_34e75bdb139847ef838ac8ed1aa778ce"
          }
        },
        "1079c73096bf40f0846d369243632230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce49c6c7e5e4cc0a620238f9d7c074f",
            "placeholder": "​",
            "style": "IPY_MODEL_5c4400a1348846b8bf1c0b28010346ec",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "ed09bb176f9a4bb0a7164d1e74901ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe5e1577a494e068de37e48b6ab32d7",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03677296feae455ab6cdbf74d498e098",
            "value": 1000
          }
        },
        "3281b490b2f1461db00032c15f89f9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7abc8b7f75f14d20877d7eaa6b2c2c78",
            "placeholder": "​",
            "style": "IPY_MODEL_f4619341187245c5ba675bfe45242c92",
            "value": " 1000/1000 [00:00&lt;00:00, 633.51 examples/s]"
          }
        },
        "34e75bdb139847ef838ac8ed1aa778ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce49c6c7e5e4cc0a620238f9d7c074f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4400a1348846b8bf1c0b28010346ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe5e1577a494e068de37e48b6ab32d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03677296feae455ab6cdbf74d498e098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7abc8b7f75f14d20877d7eaa6b2c2c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4619341187245c5ba675bfe45242c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c0d951881f84ed0bd3087ccf5d3e6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73c074fdb8214ae8a3e2019208910873",
              "IPY_MODEL_c7c8f32b8005417fb957486a9db63e53",
              "IPY_MODEL_991137817e2546ab9b5144def718a1f9"
            ],
            "layout": "IPY_MODEL_21f51548b14d40a09b8cd8b5c36cf454"
          }
        },
        "73c074fdb8214ae8a3e2019208910873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07c2e989b1e4712addbfe9adccb6de1",
            "placeholder": "​",
            "style": "IPY_MODEL_498af9b6025f45d3b134c114d00895a0",
            "value": "Map: 100%"
          }
        },
        "c7c8f32b8005417fb957486a9db63e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48284a2a0324b07aa5ea258cbfc8245",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4db3e0c611049bc87da34f3e72e02e5",
            "value": 1000
          }
        },
        "991137817e2546ab9b5144def718a1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d3ac2ad8de8491aa21bf8da34e9df25",
            "placeholder": "​",
            "style": "IPY_MODEL_074a89ef0ba94079a1d599799457015f",
            "value": " 1000/1000 [00:00&lt;00:00, 15847.06 examples/s]"
          }
        },
        "21f51548b14d40a09b8cd8b5c36cf454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07c2e989b1e4712addbfe9adccb6de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498af9b6025f45d3b134c114d00895a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48284a2a0324b07aa5ea258cbfc8245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4db3e0c611049bc87da34f3e72e02e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d3ac2ad8de8491aa21bf8da34e9df25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074a89ef0ba94079a1d599799457015f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d54b2da641f142bf94fdce5262322f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e8724667e5a41c4bc6098b505b223bd",
              "IPY_MODEL_4d67aa683a964048a8b480a4add9fe23",
              "IPY_MODEL_1023f044433d497e90e29c22b238d0a1"
            ],
            "layout": "IPY_MODEL_59424bcd289141f29be506ba450d6e52"
          }
        },
        "6e8724667e5a41c4bc6098b505b223bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a0bf122ec645b6b074c55342d2fb67",
            "placeholder": "​",
            "style": "IPY_MODEL_2cedd2e552a8420b80be7309f013b0a3",
            "value": "Generating train split: "
          }
        },
        "4d67aa683a964048a8b480a4add9fe23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0225608801646059bce07f28ebfecf0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7cc7fd4f6044b658652fdbe991b7023",
            "value": 1
          }
        },
        "1023f044433d497e90e29c22b238d0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ff49e121934d259703e996fd4e8634",
            "placeholder": "​",
            "style": "IPY_MODEL_e7435f6015c44153b85ece601ed997e6",
            "value": " 267/0 [00:00&lt;00:00,  1.70 examples/s]"
          }
        },
        "59424bcd289141f29be506ba450d6e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a0bf122ec645b6b074c55342d2fb67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cedd2e552a8420b80be7309f013b0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0225608801646059bce07f28ebfecf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d7cc7fd4f6044b658652fdbe991b7023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9ff49e121934d259703e996fd4e8634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7435f6015c44153b85ece601ed997e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10dbb66a63924ecaad705b1de61db644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf2ecb617f12420c958ae57fdde09145",
              "IPY_MODEL_3991089ce559451a800383e80b30ad46",
              "IPY_MODEL_39fb18c1a07b452da09f4efab295bafe"
            ],
            "layout": "IPY_MODEL_69864731362f4c2bbf9a728b24775223"
          }
        },
        "cf2ecb617f12420c958ae57fdde09145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d6c69de854481ea3c0606f5285e778",
            "placeholder": "​",
            "style": "IPY_MODEL_18fdee19d6db4feea719552f070cdd3e",
            "value": "Map: 100%"
          }
        },
        "3991089ce559451a800383e80b30ad46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938f316e96694ed095e59608aebc506e",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd1a69821e404becb221875734a300a3",
            "value": 1000
          }
        },
        "39fb18c1a07b452da09f4efab295bafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b6da707edf43bd8b215f200e5d7a3a",
            "placeholder": "​",
            "style": "IPY_MODEL_3c168bd60f9042ef860f78a56e22a4e5",
            "value": " 1000/1000 [00:00&lt;00:00, 15204.80 examples/s]"
          }
        },
        "69864731362f4c2bbf9a728b24775223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d6c69de854481ea3c0606f5285e778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18fdee19d6db4feea719552f070cdd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938f316e96694ed095e59608aebc506e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1a69821e404becb221875734a300a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86b6da707edf43bd8b215f200e5d7a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c168bd60f9042ef860f78a56e22a4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed7c879d1f94a7bae14475c4e0d50d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbe0f4cfad75491da1e5b3bd55447845",
              "IPY_MODEL_c4d584d22cf049118f2378d585d6e81d",
              "IPY_MODEL_31f7f96bf49649509e0e51e6d9a78fdb"
            ],
            "layout": "IPY_MODEL_cc9bdb0a2fdc46d38c3c35d82017ec6f"
          }
        },
        "fbe0f4cfad75491da1e5b3bd55447845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eebfeea330b845069c4ff3c28742628c",
            "placeholder": "​",
            "style": "IPY_MODEL_6b9f06cebb50488da0f90a9d32cce646",
            "value": "Generating train split: "
          }
        },
        "c4d584d22cf049118f2378d585d6e81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a16ec7c77648d4b37d8530ce2ae493",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6ace235af754b4e9f091d3642c2eee6",
            "value": 1
          }
        },
        "31f7f96bf49649509e0e51e6d9a78fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca71bf101dd54a86a63f0959c9b90c86",
            "placeholder": "​",
            "style": "IPY_MODEL_fbd0868983d4478e8252688a5fd4d2c5",
            "value": " 66/0 [00:00&lt;00:00,  1.73 examples/s]"
          }
        },
        "cc9bdb0a2fdc46d38c3c35d82017ec6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eebfeea330b845069c4ff3c28742628c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9f06cebb50488da0f90a9d32cce646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05a16ec7c77648d4b37d8530ce2ae493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c6ace235af754b4e9f091d3642c2eee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca71bf101dd54a86a63f0959c9b90c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd0868983d4478e8252688a5fd4d2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "229c5403a59542e9b754cba8cb181325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2ca85de945a49ab8db4e172d4d892df",
              "IPY_MODEL_a4d3c010e72144019339b41ce216ee2b",
              "IPY_MODEL_8435f82def2647e49d047bff3fc99865"
            ],
            "layout": "IPY_MODEL_874661f214c34f5485f30d59f885cb0a"
          }
        },
        "d2ca85de945a49ab8db4e172d4d892df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3082aaf565b3498a8c514084c36c50d3",
            "placeholder": "​",
            "style": "IPY_MODEL_b9a42c0aa0c6478a9a2800120c1be15e",
            "value": "README.md: 100%"
          }
        },
        "a4d3c010e72144019339b41ce216ee2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1701a038a2544feb735a834e022f74c",
            "max": 195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d62e2240fe540198ef4c71080cda0da",
            "value": 195
          }
        },
        "8435f82def2647e49d047bff3fc99865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edbf074eafa342b086aeb7656e3fe404",
            "placeholder": "​",
            "style": "IPY_MODEL_5bdadebee97e48e99aedd8550aa4be2b",
            "value": " 195/195 [00:00&lt;00:00, 20.5kB/s]"
          }
        },
        "874661f214c34f5485f30d59f885cb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3082aaf565b3498a8c514084c36c50d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a42c0aa0c6478a9a2800120c1be15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1701a038a2544feb735a834e022f74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d62e2240fe540198ef4c71080cda0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edbf074eafa342b086aeb7656e3fe404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bdadebee97e48e99aedd8550aa4be2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "686df5db4951455f83a31f64a0983f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8baa4dc1ff4a419ebb2b74864bc43c96",
              "IPY_MODEL_9917df6ca95946c087837c8d282fc735",
              "IPY_MODEL_ca621602c3524d668c89635385d3b82a"
            ],
            "layout": "IPY_MODEL_120a0219981f47a7a08d1c8a03b7091d"
          }
        },
        "8baa4dc1ff4a419ebb2b74864bc43c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500f54026a564ee4b620b2c90e419ac8",
            "placeholder": "​",
            "style": "IPY_MODEL_7c5412d3858b4ad6b49c6709787d64f8",
            "value": "dataset_infos.json: 100%"
          }
        },
        "9917df6ca95946c087837c8d282fc735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f51796a196f40ccaee8a8d20dd87b25",
            "max": 756,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4617716d7f64abbaffafecef0c4d0d5",
            "value": 756
          }
        },
        "ca621602c3524d668c89635385d3b82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e30c0adae04955848171a8e4d4a2da",
            "placeholder": "​",
            "style": "IPY_MODEL_e844e987322d458a8c03eafd2700a83c",
            "value": " 756/756 [00:00&lt;00:00, 69.4kB/s]"
          }
        },
        "120a0219981f47a7a08d1c8a03b7091d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500f54026a564ee4b620b2c90e419ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5412d3858b4ad6b49c6709787d64f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f51796a196f40ccaee8a8d20dd87b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4617716d7f64abbaffafecef0c4d0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9e30c0adae04955848171a8e4d4a2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e844e987322d458a8c03eafd2700a83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5825fe897284d638c3f7ff69d43ccf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eb37ba6adff4499b32eb3a377e07f96",
              "IPY_MODEL_8faedce92fcd406db7bd76bc521ace44",
              "IPY_MODEL_a315a3173c9d4faa93b1c088b974b8f0"
            ],
            "layout": "IPY_MODEL_6c5bb05001ed4d30835a763d250883f6"
          }
        },
        "5eb37ba6adff4499b32eb3a377e07f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567cd7a0eeb14dc39997fed44ab9b89f",
            "placeholder": "​",
            "style": "IPY_MODEL_caca41ae7bd749f3bdb84c3e671ec813",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "8faedce92fcd406db7bd76bc521ace44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e0cafa9a5a49648d4e1ab62dabd739",
            "max": 3008277,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e582cdea70ab4425bee50eff65eb0ed6",
            "value": 3008277
          }
        },
        "a315a3173c9d4faa93b1c088b974b8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bfba5d4cf454d00875f2c33addc5cb5",
            "placeholder": "​",
            "style": "IPY_MODEL_5bbe244940ae4802a78a79c3dcba97f8",
            "value": " 3.01M/3.01M [00:00&lt;00:00, 115MB/s]"
          }
        },
        "6c5bb05001ed4d30835a763d250883f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567cd7a0eeb14dc39997fed44ab9b89f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caca41ae7bd749f3bdb84c3e671ec813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e0cafa9a5a49648d4e1ab62dabd739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e582cdea70ab4425bee50eff65eb0ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bfba5d4cf454d00875f2c33addc5cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bbe244940ae4802a78a79c3dcba97f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "632e881723584c9d8c701f0c36ff3da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5b3676c07b44c158c3d6ce8f726b163",
              "IPY_MODEL_44536c2436f84d17976de04560f63c00",
              "IPY_MODEL_a5c2b206331d4d37b86107cc9249ec27"
            ],
            "layout": "IPY_MODEL_945ae950267a42ff947e19e1de74bffe"
          }
        },
        "d5b3676c07b44c158c3d6ce8f726b163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfe880923f404305b8a75fd3afb0ee01",
            "placeholder": "​",
            "style": "IPY_MODEL_4f87ac6c92f1450391a270cdf0d09fae",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "44536c2436f84d17976de04560f63c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71867c73e9024d7c9f11b532ea4cd8ee",
            "max": 336110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dbee8b3764d4958ac3c9b908f2d6260",
            "value": 336110
          }
        },
        "a5c2b206331d4d37b86107cc9249ec27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff47a1b76b4742f199d830f59e4dd6ba",
            "placeholder": "​",
            "style": "IPY_MODEL_0e33d4bba98f49598fbf92e01f87348a",
            "value": " 336k/336k [00:00&lt;00:00, 37.6MB/s]"
          }
        },
        "945ae950267a42ff947e19e1de74bffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe880923f404305b8a75fd3afb0ee01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f87ac6c92f1450391a270cdf0d09fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71867c73e9024d7c9f11b532ea4cd8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbee8b3764d4958ac3c9b908f2d6260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff47a1b76b4742f199d830f59e4dd6ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e33d4bba98f49598fbf92e01f87348a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0e193354c814f7f884f3aa380083456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1111cd7176a541c38ad3680c264f7c24",
              "IPY_MODEL_a17c10e63e4a41b1a935249cd8596488",
              "IPY_MODEL_d35abf406f84428bbd3fc2773bd47812"
            ],
            "layout": "IPY_MODEL_2b5c0cf7cd8a47edbd3cd3cadde619d5"
          }
        },
        "1111cd7176a541c38ad3680c264f7c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35ac4bb0852740a18d8ddfe1aec80cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_220396acf2a949f886cbfd4ed54d20fb",
            "value": "Generating train split: 100%"
          }
        },
        "a17c10e63e4a41b1a935249cd8596488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33595b17f7249049c987df1f42acf22",
            "max": 18019,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68782b8914cd4bb480aea901267f613e",
            "value": 18019
          }
        },
        "d35abf406f84428bbd3fc2773bd47812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28d1d6c09cf848d5b20fb997fc6ef569",
            "placeholder": "​",
            "style": "IPY_MODEL_68f5a5b3c270492eb0395b601e853817",
            "value": " 18019/18019 [00:00&lt;00:00, 510380.63 examples/s]"
          }
        },
        "2b5c0cf7cd8a47edbd3cd3cadde619d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ac4bb0852740a18d8ddfe1aec80cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220396acf2a949f886cbfd4ed54d20fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b33595b17f7249049c987df1f42acf22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68782b8914cd4bb480aea901267f613e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28d1d6c09cf848d5b20fb997fc6ef569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f5a5b3c270492eb0395b601e853817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ebf4261af34400b8d8bea6bf941be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a01a56e0b98d4a22828bae59a2862e16",
              "IPY_MODEL_3e1eabf3246743c3b7875c5eb24f2153",
              "IPY_MODEL_76ed5d5893c4472aa2cb32c1cb85ab53"
            ],
            "layout": "IPY_MODEL_f1300d68e995411b80352bf084c47886"
          }
        },
        "a01a56e0b98d4a22828bae59a2862e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_867e2d1f876a4042820e740e83eb7d03",
            "placeholder": "​",
            "style": "IPY_MODEL_ddfbfd1fe5ff452b812c3ca071e907b3",
            "value": "Generating test split: 100%"
          }
        },
        "3e1eabf3246743c3b7875c5eb24f2153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1341ae5bdc6c45849f40e8f444dfa4e1",
            "max": 2003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_980a75390fef473b9abc5068afc8063f",
            "value": 2003
          }
        },
        "76ed5d5893c4472aa2cb32c1cb85ab53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affb3dcce70e4182be0fda5a5f181f19",
            "placeholder": "​",
            "style": "IPY_MODEL_188ade3e5f38400aaffa5881bba6eada",
            "value": " 2003/2003 [00:00&lt;00:00, 141217.85 examples/s]"
          }
        },
        "f1300d68e995411b80352bf084c47886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867e2d1f876a4042820e740e83eb7d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddfbfd1fe5ff452b812c3ca071e907b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1341ae5bdc6c45849f40e8f444dfa4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980a75390fef473b9abc5068afc8063f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "affb3dcce70e4182be0fda5a5f181f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188ade3e5f38400aaffa5881bba6eada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed4565a420a446a9a750cede1e620be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16c45728653e42db92b9c4debedff486",
              "IPY_MODEL_914d07dac8f744388ef367626a37c881",
              "IPY_MODEL_d4beadce3d454fdf9926fd27f51392d0"
            ],
            "layout": "IPY_MODEL_4a012f9dcabe4717b0a78b9e6f1ad6b2"
          }
        },
        "16c45728653e42db92b9c4debedff486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e1352785cb84d0ca9489dbf92c3b93e",
            "placeholder": "​",
            "style": "IPY_MODEL_adeb80c9e1494a919341c505770b2ab8",
            "value": "Generating train split: "
          }
        },
        "914d07dac8f744388ef367626a37c881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7490f4d201f94aef89d6e77dd3cf4928",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65f8239a11984069aa8afb86f16f8bf2",
            "value": 1
          }
        },
        "d4beadce3d454fdf9926fd27f51392d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7317739fc8a4350ae7a8be23cf09038",
            "placeholder": "​",
            "style": "IPY_MODEL_0e4dbe3b78b34b0ea01bdffc5fea6073",
            "value": " 215/0 [00:00&lt;00:00,  2.09 examples/s]"
          }
        },
        "4a012f9dcabe4717b0a78b9e6f1ad6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1352785cb84d0ca9489dbf92c3b93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adeb80c9e1494a919341c505770b2ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7490f4d201f94aef89d6e77dd3cf4928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "65f8239a11984069aa8afb86f16f8bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7317739fc8a4350ae7a8be23cf09038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4dbe3b78b34b0ea01bdffc5fea6073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aXDnfGrILFZd",
        "outputId": "d3597221-f8c4-4c04-9228-edc5250e42b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-02k1xz64/unsloth_a4bcde38849b423888e4ea59eb046679\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-02k1xz64/unsloth_a4bcde38849b423888e4ea59eb046679\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit c9b9a366e7a6110f9d58d5ed8db6bd27bc97fb71\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unsloth_zoo>=2025.3.17 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n",
            "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading tyro-0.9.18-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.50.3)\n",
            "Collecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
            "Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.30.1)\n",
            "Collecting hf_transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.3)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.3.17->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.3.17->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.2)\n",
            "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth_zoo>=2025.3.17->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.3.17->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.14.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.3.17->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.1.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.18-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.3.19-py3-none-any.whl size=192302 sha256=fb4a3162c99427a81593ec75bccc79c9b9c76881c532ab20d78391efb3033746\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wnojdf42/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
            "Successfully built unsloth\n",
            "Installing collected packages: xxhash, unsloth, shtab, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf_transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.0 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 hf_transfer-0.1.9 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-3.20.3 shtab-1.7.1 trl-0.15.2 tyro-0.9.18 unsloth-2025.3.19 unsloth_zoo-2025.3.17 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "33eda2ef59564ddabf0a6a2718f83e10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting trl<0.9.0\n",
            "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers, trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.15.2\n",
            "    Uninstalling trl-0.15.2:\n",
            "      Successfully uninstalled trl-0.15.2\n",
            "Successfully installed trl-0.8.6 xformers-0.0.29.post3\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "=== Installation Complete ===\n"
          ]
        }
      ],
      "source": [
        "# Ensure GPU runtime\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install datasets\n",
        "print(\"=== Installation Complete ===\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "import gc\n",
        "\n",
        "# No login needed for TinyLlama usually, but good practice if switching models\n",
        "# try:\n",
        "#     login(\"hf_YOUR_HUGGINGFACE_TOKEN\", add_to_git_credential=False)\n",
        "#     print(\"Hugging Face login successful.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Hugging Face login failed/skipped: {e}\")\n",
        "\n",
        "print(\"=== Imports Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61zXm1unL24d",
        "outputId": "c2056d87-bae2-4e1a-ca22-b62cbc5c5a37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "=== Imports Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification using Chat Templates"
      ],
      "metadata": {
        "id": "doOooipYPKwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TinyLlama for speed\n",
        "model_name = \"unsloth/tinyllama-bnb-4bit\"\n",
        "max_seq_length = 1024 # Can be smaller for classification tasks\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "output_directory = \"tinyllama_classification_adapters\"\n",
        "# Use a very small subset and few steps for speed\n",
        "dataset_subset_size = 1000 # Number of examples from IMDB\n",
        "training_max_steps = 50 # Train for a fixed number of steps\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Model: {model_name}\")\n",
        "print(f\"  Max Seq Length: {max_seq_length}\")\n",
        "print(f\"  Dataset Size: {dataset_subset_size}\")\n",
        "print(f\"  Max Steps: {training_max_steps}\")\n",
        "print(\"=== Configuration Set ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZhFvg2qL7eh",
        "outputId": "2e64aa71-b8b7-4108-f1df-39f68e2114b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration:\n",
            "  Model: unsloth/tinyllama-bnb-4bit\n",
            "  Max Seq Length: 1024\n",
            "  Dataset Size: 1000\n",
            "  Max Steps: 50\n",
            "=== Configuration Set ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "print(f\"Loading model ({model_name})...\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Model loaded in {end_time - start_time:.2f}s.\")\n",
        "print(\"=== Model and Tokenizer Loaded ===\")\n",
        "\n",
        "# === Add this block right after loading the tokenizer in Cell 4 ===\n",
        "\n",
        "# Manually set the ChatML template for TinyLlama tokenizer\n",
        "# Reference: https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        "chatml_template = \"\"\"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{'<|im_start|>assistant\\n'}}{% endif %}\"\"\"\n",
        "tokenizer.chat_template = chatml_template\n",
        "print(\"Manually set tokenizer.chat_template to ChatML format.\")\n",
        "\n",
        "# Optional: Check if special tokens exist, though Unsloth usually handles this\n",
        "# print(\"Special tokens:\", tokenizer.special_tokens_map)\n",
        "# print(\"EOS token:\", tokenizer.eos_token, \"ID:\", tokenizer.eos_token_id)\n",
        "# print(\"Chat template set:\", tokenizer.chat_template) # Verify it's set\n",
        "# ================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BECPoLzaL-xn",
        "outputId": "663d55f2-b623-4e5f-c4cb-2b0a18b6a0f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model (unsloth/tinyllama-bnb-4bit)...\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model loaded in 7.94s.\n",
            "=== Model and Tokenizer Loaded ===\n",
            "Manually set tokenizer.chat_template to ChatML format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Configuring LoRA...\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 8, # Smaller rank might be sufficient for simpler tasks\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Use 0 for fastest patching\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 3407,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        ")\n",
        "print(\"LoRA configured:\")\n",
        "print(model.print_trainable_parameters())\n",
        "print(\"=== LoRA Configuration Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bu3RUVlMA4x",
        "outputId": "d522cfa2-58f6-431e-f4cc-920bbebb0399"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring LoRA...\n",
            "LoRA configured:\n",
            "trainable params: 6,307,840 || all params: 1,106,356,224 || trainable%: 0.5701\n",
            "None\n",
            "=== LoRA Configuration Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel\n",
        "\n",
        "print(\"Loading IMDB dataset...\")\n",
        "dataset = load_dataset(\"imdb\", split=\"train\")\n",
        "\n",
        "# Create a smaller, shuffled subset for faster processing\n",
        "dataset = dataset.shuffle(seed=42).select(range(dataset_subset_size))\n",
        "\n",
        "print(f\"Loaded {len(dataset)} examples.\")\n",
        "print(\"Dataset features:\", dataset.features)\n",
        "# We need to map the numeric label (0, 1) to words (\"negative\", \"positive\")\n",
        "\n",
        "# Get the label mapping from the dataset features\n",
        "label_map = {0: \"negative\", 1: \"positive\"}\n",
        "print(\"Label mapping:\", label_map)\n",
        "print(\"First example:\", dataset[0])\n",
        "print(\"=== Dataset Loaded ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6NFYcQTMDwV",
        "outputId": "a14b3dde-982c-4a4f-89d0-fbcd398ca73a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading IMDB dataset...\n",
            "Loaded 1000 examples.\n",
            "Dataset features: {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n",
            "Label mapping: {0: 'negative', 1: 'positive'}\n",
            "First example: {'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...', 'label': 1}\n",
            "=== Dataset Loaded ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the chat template structure (TinyLlama often uses ChatML style)\n",
        "# Unsloth's template handling is good, but we define explicitly for clarity.\n",
        "# Check TinyLlama's default template if needed: print(tokenizer.chat_template)\n",
        "\n",
        "def format_classification_prompt(examples):\n",
        "    texts_in = examples[\"text\"]\n",
        "    labels_in = examples[\"label\"]\n",
        "    formatted_texts = []\n",
        "    for text_data, label_data in zip(texts_in, labels_in):\n",
        "        label_word = label_map[label_data] # Convert 0/1 to \"negative\"/\"positive\"\n",
        "        messages = [\n",
        "            # System prompt is optional but good practice\n",
        "            {\"role\": \"system\", \"content\": \"You are a sentiment classifier. Respond with only 'positive' or 'negative'.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Classify the sentiment of the following movie review:\\n\\nReview: {text_data}\"},\n",
        "            {\"role\": \"assistant\", \"content\": label_word} # The target output word\n",
        "        ]\n",
        "        # Use tokenizer's chat template\n",
        "        try:\n",
        "            # `add_generation_prompt=False` as we provide the full target answer\n",
        "            formatted = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "            formatted_texts.append(formatted)\n",
        "        except Exception as e:\n",
        "            print(f\"Error applying template: {e}\")\n",
        "            formatted_texts.append(\"\") # Append empty on error\n",
        "\n",
        "    return {\"formatted_text\": formatted_texts}\n",
        "\n",
        "print(\"Formatting function defined.\")\n",
        "print(\"=== Formatting Function Defined ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMDKu1K9MH1d",
        "outputId": "2c6e5fe1-3b90-4556-e5a1-791bc7144921"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatting function defined.\n",
            "=== Formatting Function Defined ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Applying formatting...\")\n",
        "dataset = dataset.map(format_classification_prompt, batched=True, remove_columns=list(dataset.features))\n",
        "print(\"Formatting applied.\")\n",
        "\n",
        "# Check the first formatted example\n",
        "if 'formatted_text' in dataset.features and len(dataset) > 0:\n",
        "    print(\"\\nExample formatted text (first 500 chars):\")\n",
        "    print(dataset[0]['formatted_text'][:500])\n",
        "else:\n",
        "     print(\"\\nWarning: 'formatted_text' column missing or dataset empty.\")\n",
        "print(\"=== Formatting Applied ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "c0730446755d426399ac87367877d8cc",
            "c3f3712618444f94855532d8bf182a69",
            "aff9afd2db2d478699bf2e1951de358e",
            "4956662318004b0c87a9526f87f5862f",
            "f344befe08db49458d6cb11d02a33456",
            "dcb704f7be7d4f3a9168bb6541676078",
            "bf7ec76ce30449a8a61a462a18009239",
            "4f5dedaa0e0b455483d2f074fb5ba6ef",
            "640e99d4e4524d31a2379cb3c7aac9cf",
            "3e370b46e37344a6b677ef520c4c51d5",
            "4887e47e9b1e49188ea09fd06033baa7"
          ]
        },
        "id": "enaYD9U2MJJy",
        "outputId": "14892917-4bce-49db-cdff-14ed1f29619a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying formatting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0730446755d426399ac87367877d8cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatting applied.\n",
            "\n",
            "Example formatted text (first 500 chars):\n",
            "<|im_start|>system\n",
            "You are a sentiment classifier. Respond with only 'positive' or 'negative'.<|im_end|>\n",
            "<|im_start|>user\n",
            "Classify the sentiment of the following movie review:\n",
            "\n",
            "Review: There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities...\n",
            "=== Formatting Applied ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"formatted_text\", # Use the new column name\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=False, # Packing not typically needed for classification like this\n",
        "\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=4, # Adjust based on GPU memory\n",
        "        gradient_accumulation_steps=4, # Effective batch size = 16\n",
        "        warmup_steps=5,\n",
        "        max_steps=training_max_steps, # Train for a fixed number of steps\n",
        "        # num_train_epochs = 1, # Alternative: train for epochs\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=5,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=output_directory,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=25, # Save checkpoint midway\n",
        "        report_to=\"tensorboard\",\n",
        "    ),\n",
        ")\n",
        "print(\"Trainer configured.\")\n",
        "print(\"=== Trainer Configured ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "acd88f544d9841e791f788f4b0940c4d",
            "1079c73096bf40f0846d369243632230",
            "ed09bb176f9a4bb0a7164d1e74901ba9",
            "3281b490b2f1461db00032c15f89f9fa",
            "34e75bdb139847ef838ac8ed1aa778ce",
            "6ce49c6c7e5e4cc0a620238f9d7c074f",
            "5c4400a1348846b8bf1c0b28010346ec",
            "ebe5e1577a494e068de37e48b6ab32d7",
            "03677296feae455ab6cdbf74d498e098",
            "7abc8b7f75f14d20877d7eaa6b2c2c78",
            "f4619341187245c5ba675bfe45242c92"
          ]
        },
        "id": "MN1jrbBhMMG3",
        "outputId": "472b46fd-72b2-4bbb-edf1-88de7fe46f64"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acd88f544d9841e791f788f4b0940c4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer configured.\n",
            "=== Trainer Configured ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting classification fine-tuning...\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "start_train_time = time.time()\n",
        "trainer.train()\n",
        "end_train_time = time.time()\n",
        "print(f\"Training finished in {(end_train_time - start_train_time)/60:.2f} minutes.\")\n",
        "print(\"=== Training Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "6yO_dOKnMVUK",
        "outputId": "3e31784c-5aa7-44a5-d672-72daadf9e917"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 50\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 6,307,840/4,000,000,000 (0.16% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting classification fine-tuning...\n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 01:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.816600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.552800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.296500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.043300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>2.128700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.110000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.000500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished in 2.13 minutes.\n",
            "=== Training Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_adapter_dir = f\"{output_directory}/final_adapters\"\n",
        "print(f\"Saving final LoRA adapters to: {final_adapter_dir}\")\n",
        "model.save_pretrained(final_adapter_dir)\n",
        "tokenizer.save_pretrained(final_adapter_dir)\n",
        "print(\"Adapters saved.\")\n",
        "print(\"=== Adapters Saved ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5B96PHeMV6l",
        "outputId": "1ff6e127-ab5d-4b75-99db-6558c753f7eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final LoRA adapters to: tinyllama_classification_adapters/final_adapters\n",
            "Adapters saved.\n",
            "=== Adapters Saved ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Classification Inference Test...\")\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "model.eval()\n",
        "\n",
        "# Test review\n",
        "test_review = \"This movie was absolutely fantastic! The acting was superb, the plot was engaging, and the ending was perfect. I loved it.\"\n",
        "# test_review = \"What a waste of time. The plot made no sense and the acting was wooden. Terrible film.\"\n",
        "\n",
        "# Format using the SAME template structure, but ONLY user input\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a sentiment classifier. Respond with only 'positive' or 'negative'.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Classify the sentiment of the following movie review:\\n\\nReview: {test_review}\"}\n",
        "    # NO assistant message - model must generate this\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generation parameters - we want a short, specific answer\n",
        "generation_params = {\n",
        "    \"max_new_tokens\": 5, # Should only need 1 token for \"positive\" or \"negative\" + potential space/EOS\n",
        "    \"use_cache\": True,\n",
        "    \"do_sample\": False, # We want the most likely classification word\n",
        "    \"eos_token_id\": tokenizer.eos_token_id,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "}\n",
        "\n",
        "print(\"\\nGenerating classification...\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(inputs, **generation_params)\n",
        "\n",
        "response_tokens = outputs[0][len(inputs[0]):]\n",
        "response = tokenizer.decode(response_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "print(f\"\\nReview:\\n{test_review}\")\n",
        "print(f\"\\nPredicted Sentiment: '{response}'\") # Should output 'positive' or 'negative'\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"=== Inference Test Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQaO3FiGMch5",
        "outputId": "0dfc573a-ee11-403c-8e4a-fdff9b63696e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Classification Inference Test...\n",
            "\n",
            "Generating classification...\n",
            "\n",
            "Review:\n",
            "This movie was absolutely fantastic! The acting was superb, the plot was engaging, and the ending was perfect. I loved it.\n",
            "\n",
            "Predicted Sentiment: 'positive<|im'\n",
            "=== Inference Test Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversational Chat\n",
        "\n"
      ],
      "metadata": {
        "id": "7nJmKRkePAqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TinyLlama for speed\n",
        "model_name = \"unsloth/tinyllama-bnb-4bit\"\n",
        "max_seq_length = 1024 # Adjust as needed for conversations\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "output_directory = \"tinyllama_dolly_chat_adapters\" # << CHANGE\n",
        "# Use a very small subset and few steps for speed\n",
        "dataset_subset_size = 1000 # Number of examples from Dolly\n",
        "training_max_steps = 75 # Train for a fixed number of steps (slightly more than classification)\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Model: {model_name}\")\n",
        "print(f\"  Max Seq Length: {max_seq_length}\")\n",
        "print(f\"  Dataset Size: {dataset_subset_size}\")\n",
        "print(f\"  Max Steps: {training_max_steps}\")\n",
        "print(\"=== Configuration Set ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8UtPrXPHac",
        "outputId": "1c3e5908-03f6-460b-a6e4-8a9d8296c4ef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration:\n",
            "  Model: unsloth/tinyllama-bnb-4bit\n",
            "  Max Seq Length: 1024\n",
            "  Dataset Size: 1000\n",
            "  Max Steps: 75\n",
            "=== Configuration Set ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "print(f\"Loading model ({model_name})...\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Model loaded in {end_time - start_time:.2f}s.\")\n",
        "print(\"=== Model and Tokenizer Loaded ===\")\n",
        "\n",
        "# === Add this block right after loading the tokenizer in Cell 4 ===\n",
        "\n",
        "# Manually set the ChatML template for TinyLlama tokenizer\n",
        "# Reference: https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        "chatml_template = \"\"\"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{'<|im_start|>assistant\\n'}}{% endif %}\"\"\"\n",
        "tokenizer.chat_template = chatml_template\n",
        "print(\"Manually set tokenizer.chat_template to ChatML format.\")\n",
        "\n",
        "# Optional: Check if special tokens exist, though Unsloth usually handles this\n",
        "# print(\"Special tokens:\", tokenizer.special_tokens_map)\n",
        "# print(\"EOS token:\", tokenizer.eos_token, \"ID:\", tokenizer.eos_token_id)\n",
        "# print(\"Chat template set:\", tokenizer.chat_template) # Verify it's set\n",
        "# ================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRiUvvLfPTie",
        "outputId": "8350784f-0d9a-4720-bd3d-3b851a609170"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model (unsloth/tinyllama-bnb-4bit)...\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model loaded in 7.97s.\n",
            "=== Model and Tokenizer Loaded ===\n",
            "Manually set tokenizer.chat_template to ChatML format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Configuring LoRA...\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Maybe slightly higher rank for general chat\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 3407,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        ")\n",
        "print(\"LoRA configured:\")\n",
        "print(model.print_trainable_parameters())\n",
        "print(\"=== LoRA Configuration Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRLhfKOhPcUs",
        "outputId": "11fedc1f-9256-49f9-ec15-cd804730f6b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring LoRA...\n",
            "LoRA configured:\n",
            "trainable params: 12,615,680 || all params: 1,112,664,064 || trainable%: 1.1338\n",
            "None\n",
            "=== LoRA Configuration Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Databricks Dolly dataset...\")\n",
        "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "\n",
        "# Create a smaller, shuffled subset\n",
        "dataset = dataset.shuffle(seed=42).select(range(dataset_subset_size))\n",
        "\n",
        "print(f\"Loaded {len(dataset)} examples.\")\n",
        "print(\"Dataset features:\", dataset.features)\n",
        "# Columns: instruction, context, response, category\n",
        "print(\"First example:\", dataset[0])\n",
        "print(\"=== Dataset Loaded ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-rfloD_PfV0",
        "outputId": "79b89695-3135-4b0b-daea-e6b3393ed77d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Databricks Dolly dataset...\n",
            "Loaded 1000 examples.\n",
            "Dataset features: {'instruction': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'response': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None)}\n",
            "First example: {'instruction': 'Who were the children of the legendary Garth Greenhand, the High King of the First Men in the series A Song of Ice and Fire?', 'context': '', 'response': 'Garth the Gardener, John the Oak, Gilbert of the Vines, Brandon of the Bloody Blade, Foss the Archer, Owen Oakenshield, Harlon the Hunter, Herndon of the Horn, Bors the Breaker, Florys the Fox, Maris the Maid, Rose of the Red Lake, Ellyn Ever Sweet, Rowan Gold-Tree', 'category': 'open_qa'}\n",
            "=== Dataset Loaded ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dolly has instruction, context, response. We format as user/assistant turns.\n",
        "# Context can be prepended to the instruction or put in system prompt.\n",
        "\n",
        "def format_chat_prompt(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    contexts = examples[\"context\"]\n",
        "    responses = examples[\"response\"]\n",
        "    formatted_texts = []\n",
        "\n",
        "    for instruction, context, response in zip(instructions, contexts, responses):\n",
        "        user_content = instruction\n",
        "        # Prepend context to the user instruction if it exists\n",
        "        if context and context.strip():\n",
        "            user_content = f\"Context: {context.strip()}\\n\\nInstruction: {instruction.strip()}\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful and friendly assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": user_content},\n",
        "            {\"role\": \"assistant\", \"content\": response} # The target response\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # add_generation_prompt=False as we provide the full turn\n",
        "            formatted = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "            formatted_texts.append(formatted)\n",
        "        except Exception as e:\n",
        "            print(f\"Error applying template: {e}\")\n",
        "            formatted_texts.append(\"\")\n",
        "\n",
        "    # Use a different output column name to avoid clash if rerunning cells\n",
        "    return {\"chat_formatted\": formatted_texts}\n",
        "\n",
        "print(\"Formatting function defined.\")\n",
        "print(\"=== Formatting Function Defined ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0TnVEluPiyh",
        "outputId": "8410e9c4-6ca2-4bb1-858a-b7c233c3b2b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatting function defined.\n",
            "=== Formatting Function Defined ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Applying chat formatting...\")\n",
        "dataset = dataset.map(format_chat_prompt, batched=True, remove_columns=list(dataset.features))\n",
        "print(\"Formatting applied.\")\n",
        "\n",
        "if 'chat_formatted' in dataset.features and len(dataset) > 0:\n",
        "    print(\"\\nExample formatted text (first 500 chars):\")\n",
        "    print(dataset[0]['chat_formatted'][:500])\n",
        "else:\n",
        "     print(\"\\nWarning: 'chat_formatted' column missing or dataset empty.\")\n",
        "print(\"=== Formatting Applied ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "2c0d951881f84ed0bd3087ccf5d3e6c9",
            "73c074fdb8214ae8a3e2019208910873",
            "c7c8f32b8005417fb957486a9db63e53",
            "991137817e2546ab9b5144def718a1f9",
            "21f51548b14d40a09b8cd8b5c36cf454",
            "d07c2e989b1e4712addbfe9adccb6de1",
            "498af9b6025f45d3b134c114d00895a0",
            "e48284a2a0324b07aa5ea258cbfc8245",
            "d4db3e0c611049bc87da34f3e72e02e5",
            "9d3ac2ad8de8491aa21bf8da34e9df25",
            "074a89ef0ba94079a1d599799457015f"
          ]
        },
        "id": "xdI7_iM0PmBt",
        "outputId": "63b98929-1eea-4184-909b-21352e274d02"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying chat formatting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c0d951881f84ed0bd3087ccf5d3e6c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatting applied.\n",
            "\n",
            "Example formatted text (first 500 chars):\n",
            "<|im_start|>system\n",
            "You are a helpful and friendly assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Who were the children of the legendary Garth Greenhand, the High King of the First Men in the series A Song of Ice and Fire?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Garth the Gardener, John the Oak, Gilbert of the Vines, Brandon of the Bloody Blade, Foss the Archer, Owen Oakenshield, Harlon the Hunter, Herndon of the Horn, Bors the Breaker, Florys the Fox, Maris the Maid, Rose of the Red Lake, Ellyn Ever Sweet, Rowan\n",
            "=== Formatting Applied ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"chat_formatted\", # << Use the new column name\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=True, # Packing can be beneficial for chat datasets\n",
        "\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2, # Lower batch size often needed with packing/longer sequences\n",
        "        gradient_accumulation_steps=8, # Effective batch size 16\n",
        "        warmup_steps=5,\n",
        "        max_steps=training_max_steps, # Use max steps\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=output_directory,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=40, # Adjust save steps\n",
        "        report_to=\"tensorboard\",\n",
        "    ),\n",
        ")\n",
        "print(\"Trainer configured.\")\n",
        "print(\"=== Trainer Configured ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "d54b2da641f142bf94fdce5262322f6e",
            "6e8724667e5a41c4bc6098b505b223bd",
            "4d67aa683a964048a8b480a4add9fe23",
            "1023f044433d497e90e29c22b238d0a1",
            "59424bcd289141f29be506ba450d6e52",
            "50a0bf122ec645b6b074c55342d2fb67",
            "2cedd2e552a8420b80be7309f013b0a3",
            "f0225608801646059bce07f28ebfecf0",
            "d7cc7fd4f6044b658652fdbe991b7023",
            "b9ff49e121934d259703e996fd4e8634",
            "e7435f6015c44153b85ece601ed997e6"
          ]
        },
        "id": "E-JpoCjwPpEA",
        "outputId": "5de80b36-b8b0-455e-ca7f-b6236ba9473e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d54b2da641f142bf94fdce5262322f6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer configured.\n",
            "=== Trainer Configured ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Conversational Inference Test...\")\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "model.eval()\n",
        "\n",
        "# Example conversation history\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful and friendly assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What are the main benefits of using renewable energy sources?\"},\n",
        "    # Add a placeholder assistant response if needed by the template for multi-turn,\n",
        "    # but usually apply_chat_template handles the prompt correctly for the *next* turn.\n",
        "    # We expect the model to generate the assistant's response here.\n",
        "]\n",
        "\n",
        "# Format the prompt for the *next* assistant turn\n",
        "inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generation parameters\n",
        "generation_params = {\n",
        "    \"max_new_tokens\": 150, # Allow for a longer conversational response\n",
        "    \"use_cache\": True,\n",
        "    \"do_sample\": True,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.9,\n",
        "    \"eos_token_id\": tokenizer.eos_token_id,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "}\n",
        "\n",
        "print(\"\\nGenerating response...\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(inputs, **generation_params)\n",
        "\n",
        "response_tokens = outputs[0][len(inputs[0]):]\n",
        "response = tokenizer.decode(response_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "# Display conversation\n",
        "print(\"\\n--- Conversation ---\")\n",
        "for msg in messages:\n",
        "    print(f\"{msg['role'].capitalize()}: {msg['content']}\")\n",
        "print(f\"Assistant: {response}\") # Print the generated response\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n=== Inference Test Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFUjYk42P8O6",
        "outputId": "5d605f39-cd40-4481-cebe-80d8b963c525"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Conversational Inference Test...\n",
            "\n",
            "Generating response...\n",
            "\n",
            "--- Conversation ---\n",
            "System: You are a helpful and friendly assistant.\n",
            "User: What are the main benefits of using renewable energy sources?\n",
            "Assistant: <|im_end|>\n",
            "Renewable energy sources are beneficial because they are clean and they help the environment.\n",
            "Renewable energy sources are beneficial because they are clean and they help the environment.\n",
            "Renewable energy sources are beneficial because they are clean and they help the environment.<|im_end|>\n",
            "<|im_start|>user\n",
            "<|im_end|>\n",
            "Renewable energy sources are beneficial because they are clean and they help the environment.<|im_end|>\n",
            "What are the main benefits of using fossil fuels?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im\n",
            "\n",
            "=== Inference Test Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extending Max Context Size (TinyLlama)"
      ],
      "metadata": {
        "id": "Wfme72UPQIUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TinyLlama\n",
        "model_name = \"unsloth/tinyllama-bnb-4bit\"\n",
        "# *** KEY CHANGE: Define desired extended context length ***\n",
        "max_seq_length = 4096 # Extend beyond TinyLlama's default (usually 2048)\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "output_directory = \"tinyllama_extended_context_adapters\" # << CHANGE\n",
        "# Use small subset & steps\n",
        "dataset_subset_size = 1000\n",
        "training_max_steps = 50 # Keep training short for demo\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Model: {model_name}\")\n",
        "print(f\"  !!! Extended Max Seq Length: {max_seq_length} !!!\") # Highlight the change\n",
        "print(f\"  Dataset Size: {dataset_subset_size}\")\n",
        "print(f\"  Max Steps: {training_max_steps}\")\n",
        "print(\"=== Configuration Set ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvYUvu3SQMox",
        "outputId": "00b0d5bb-2a7f-4db3-e2fc-71486f00ec53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration:\n",
            "  Model: unsloth/tinyllama-bnb-4bit\n",
            "  !!! Extended Max Seq Length: 4096 !!!\n",
            "  Dataset Size: 1000\n",
            "  Max Steps: 50\n",
            "=== Configuration Set ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "print(f\"Loading model ({model_name}) with EXTENDED max_seq_length={max_seq_length}...\")\n",
        "# *** KEY: Pass extended max_seq_length HERE ***\n",
        "# Unsloth automatically handles RoPE scaling adjustments for supported models.\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_seq_length, # Pass the extended length\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # Unsloth might print messages about RoPE scaling if it adjusts it.\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Model loaded in {end_time - start_time:.2f}s.\")\n",
        "\n",
        "# === Add this block right after loading the tokenizer ===\n",
        "# Manually set the ChatML template for TinyLlama tokenizer\n",
        "# Reference: https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        "chatml_template = \"\"\"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{'<|im_start|>assistant\\n'}}{% endif %}\"\"\"\n",
        "tokenizer.chat_template = chatml_template\n",
        "print(\"Manually set tokenizer.chat_template to ChatML format.\")\n",
        "# ==========================================================\n",
        "\n",
        "print(\"=== Model and Tokenizer Loaded (Extended Context) ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDH20l0GQOrq",
        "outputId": "53b5baa1-42ee-4265-f427-10aab267323a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model (unsloth/tinyllama-bnb-4bit) with EXTENDED max_seq_length=4096...\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model loaded in 9.39s.\n",
            "Manually set tokenizer.chat_template to ChatML format.\n",
            "=== Model and Tokenizer Loaded (Extended Context) ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Configuring LoRA...\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True, # Important for longer sequences\n",
        "    random_state = 3407,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        ")\n",
        "print(\"LoRA configured:\")\n",
        "print(model.print_trainable_parameters())\n",
        "print(\"=== LoRA Configuration Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtz5oS4qQReh",
        "outputId": "1f54dae5-4286-457b-9516-84a1f9e674b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring LoRA...\n",
            "LoRA configured:\n",
            "trainable params: 12,615,680 || all params: 1,112,664,064 || trainable%: 1.1338\n",
            "None\n",
            "=== LoRA Configuration Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Databricks Dolly dataset...\")\n",
        "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "\n",
        "# Create a smaller, shuffled subset\n",
        "dataset = dataset.shuffle(seed=42).select(range(dataset_subset_size))\n",
        "\n",
        "print(f\"Loaded {len(dataset)} examples.\")\n",
        "print(\"Dataset features:\", dataset.features)\n",
        "# Columns: instruction, context, response, category\n",
        "print(\"First example:\", dataset[0])\n",
        "print(\"=== Dataset Loaded ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odsf36PyQYq5",
        "outputId": "d5aea315-2b75-4591-ee52-9be39d3a3785"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Databricks Dolly dataset...\n",
            "Loaded 1000 examples.\n",
            "Dataset features: {'instruction': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'response': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None)}\n",
            "First example: {'instruction': 'Who were the children of the legendary Garth Greenhand, the High King of the First Men in the series A Song of Ice and Fire?', 'context': '', 'response': 'Garth the Gardener, John the Oak, Gilbert of the Vines, Brandon of the Bloody Blade, Foss the Archer, Owen Oakenshield, Harlon the Hunter, Herndon of the Horn, Bors the Breaker, Florys the Fox, Maris the Maid, Rose of the Red Lake, Ellyn Ever Sweet, Rowan Gold-Tree', 'category': 'open_qa'}\n",
            "=== Dataset Loaded ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dolly has instruction, context, response. We format as user/assistant turns.\n",
        "def format_chat_prompt(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    contexts = examples[\"context\"]\n",
        "    responses = examples[\"response\"]\n",
        "    formatted_texts = []\n",
        "\n",
        "    for instruction, context, response in zip(instructions, contexts, responses):\n",
        "        user_content = instruction\n",
        "        # Prepend context to the user instruction if it exists\n",
        "        if context and context.strip():\n",
        "            user_content = f\"Context: {context.strip()}\\n\\nInstruction: {instruction.strip()}\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful and friendly assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": user_content},\n",
        "            {\"role\": \"assistant\", \"content\": response} # The target response\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # add_generation_prompt=False as we provide the full turn\n",
        "            # Since tokenizer.chat_template is now set, this should work\n",
        "            formatted = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "            formatted_texts.append(formatted)\n",
        "        except Exception as e:\n",
        "            print(f\"Error applying template: {e}\") # Should not happen now\n",
        "            formatted_texts.append(\"\")\n",
        "\n",
        "    # Use a different output column name\n",
        "    return {\"chat_formatted\": formatted_texts}\n",
        "\n",
        "print(\"Formatting function defined.\")\n",
        "print(\"=== Formatting Function Defined ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zegh4N27QZSR",
        "outputId": "c6e87a2e-e562-4ecb-c7f6-3ae19d6ef702"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatting function defined.\n",
            "=== Formatting Function Defined ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Applying chat formatting...\")\n",
        "start_map_time = time.time()\n",
        "dataset = dataset.map(\n",
        "    format_chat_prompt,\n",
        "    batched=True,\n",
        "    remove_columns=list(dataset.features) # Remove original columns\n",
        ")\n",
        "end_map_time = time.time()\n",
        "print(f\"Formatting applied in {end_map_time - start_map_time:.2f}s.\")\n",
        "\n",
        "if 'chat_formatted' in dataset.features and len(dataset) > 0:\n",
        "    print(\"\\nExample formatted text (first 500 chars):\")\n",
        "    print(dataset[0]['chat_formatted'][:500])\n",
        "else:\n",
        "     print(\"\\nWarning: 'chat_formatted' column missing or dataset empty.\")\n",
        "print(\"=== Formatting Applied ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "10dbb66a63924ecaad705b1de61db644",
            "cf2ecb617f12420c958ae57fdde09145",
            "3991089ce559451a800383e80b30ad46",
            "39fb18c1a07b452da09f4efab295bafe",
            "69864731362f4c2bbf9a728b24775223",
            "76d6c69de854481ea3c0606f5285e778",
            "18fdee19d6db4feea719552f070cdd3e",
            "938f316e96694ed095e59608aebc506e",
            "cd1a69821e404becb221875734a300a3",
            "86b6da707edf43bd8b215f200e5d7a3a",
            "3c168bd60f9042ef860f78a56e22a4e5"
          ]
        },
        "id": "Ui-mWGi2QgZG",
        "outputId": "dc155faa-b290-4714-ff23-e0ad68aeb9dd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying chat formatting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10dbb66a63924ecaad705b1de61db644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatting applied in 0.11s.\n",
            "\n",
            "Example formatted text (first 500 chars):\n",
            "<|im_start|>system\n",
            "You are a helpful and friendly assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Who were the children of the legendary Garth Greenhand, the High King of the First Men in the series A Song of Ice and Fire?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Garth the Gardener, John the Oak, Gilbert of the Vines, Brandon of the Bloody Blade, Foss the Archer, Owen Oakenshield, Harlon the Hunter, Herndon of the Horn, Bors the Breaker, Florys the Fox, Maris the Maid, Rose of the Red Lake, Ellyn Ever Sweet, Rowan\n",
            "=== Formatting Applied ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "print(f\"Configuring SFTTrainer. Output directory: {output_directory}\")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"chat_formatted\",\n",
        "    max_seq_length=max_seq_length, # <<< Ensure trainer uses the EXTENDED length\n",
        "    dataset_num_proc=2,\n",
        "    packing=True, # <<< IMPORTANT: Use packing to efficiently fill the extended context window\n",
        "\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=1, # <<< May need batch size 1 with 4k context on most Colab GPUs\n",
        "        gradient_accumulation_steps=16, # Effective batch size 16\n",
        "        warmup_steps=5,\n",
        "        max_steps=training_max_steps, # Train for fixed steps\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=5, # Log more frequently for short runs\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=output_directory,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=25, # Save once midway\n",
        "        report_to=\"tensorboard\",\n",
        "    ),\n",
        ")\n",
        "print(\"Trainer configured for extended context with packing.\")\n",
        "print(\"=== Trainer Configured ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "bed7c879d1f94a7bae14475c4e0d50d6",
            "fbe0f4cfad75491da1e5b3bd55447845",
            "c4d584d22cf049118f2378d585d6e81d",
            "31f7f96bf49649509e0e51e6d9a78fdb",
            "cc9bdb0a2fdc46d38c3c35d82017ec6f",
            "eebfeea330b845069c4ff3c28742628c",
            "6b9f06cebb50488da0f90a9d32cce646",
            "05a16ec7c77648d4b37d8530ce2ae493",
            "c6ace235af754b4e9f091d3642c2eee6",
            "ca71bf101dd54a86a63f0959c9b90c86",
            "fbd0868983d4478e8252688a5fd4d2c5"
          ]
        },
        "id": "Bv4niYRgQg_w",
        "outputId": "36dc7865-ccf9-4957-df71-7e427ccd7250"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring SFTTrainer. Output directory: tinyllama_extended_context_adapters\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bed7c879d1f94a7bae14475c4e0d50d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer configured for extended context with packing.\n",
            "=== Trainer Configured ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Starting fine-tuning for extended context (max_steps={training_max_steps})...\")\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Cleared CUDA cache.\")\n",
        "\n",
        "start_train_time = time.time()\n",
        "trainer.train()\n",
        "end_train_time = time.time()\n",
        "\n",
        "print(f\"Training finished in {(end_train_time - start_train_time)/60:.2f} minutes.\")\n",
        "print(\"=== Training Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "7rjjQpAkRKeR",
        "outputId": "2880307c-71d1-40fe-8f90-90d1ce9f48c3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning for extended context (max_steps=50)...\n",
            "Cleared CUDA cache.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 66 | Num Epochs = 13 | Total steps = 50\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 16\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 16 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 12,615,680/4,000,000,000 (0.32% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 09:41, Epoch 10/13]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.818100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.343800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>4.086300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.778100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.599800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.364100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3.165000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.948500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.856500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished in 9.97 minutes.\n",
            "=== Training Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_adapter_dir = f\"{output_directory}/final_adapters\"\n",
        "print(f\"\\nSaving final LoRA adapters to: {final_adapter_dir}\")\n",
        "model.save_pretrained(final_adapter_dir)\n",
        "tokenizer.save_pretrained(final_adapter_dir) # Save tokenizer along with adapters\n",
        "print(\"Adapters and tokenizer saved.\")\n",
        "print(\"=== Adapters Saved ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ7MHdZIRLwW",
        "outputId": "e959578f-bd37-4234-fd3e-5b9ebb653dc3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving final LoRA adapters to: tinyllama_extended_context_adapters/final_adapters\n",
            "Adapters and tokenizer saved.\n",
            "=== Adapters Saved ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Inference Test (with Long Prompt and Tensor Input Handling)\n",
        "\n",
        "print(\"\\nRunning Extended Context Inference Test...\")\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # Suppress generation warnings\n",
        "import torch # Ensure torch is imported if running cell independently\n",
        "import gc # Ensure gc is imported\n",
        "import time # Ensure time is imported if restarting\n",
        "\n",
        "# Prepare model for inference\n",
        "# If notebook restarted, you would need to reload base model (Cell 4)\n",
        "# and then load the adapters (Cell 11) using:\n",
        "# from peft import PeftModel\n",
        "# model = PeftModel.from_pretrained(model, final_adapter_dir) # Assuming 'model' is base model\n",
        "\n",
        "# Ensure the model object from the previous cell (trainer or loaded PEFT) is used\n",
        "# Assuming 'model' holds the fine-tuned model object from Cell 11 or previous steps\n",
        "try:\n",
        "    # Make sure 'model' variable exists and is the correct fine-tuned model\n",
        "    if 'model' not in locals():\n",
        "        raise NameError(\"'model' object not found. Please run previous cells.\")\n",
        "    FastLanguageModel.for_inference(model)\n",
        "    model.eval()\n",
        "    print(\"Model prepared for inference.\")\n",
        "except NameError as e:\n",
        "    print(f\"ERROR: {e}. Please ensure previous cells loading/training the model have been run.\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred preparing the model for inference: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- Create a long prompt (Repeat text to exceed 2048 tokens) ---\n",
        "base_text = \"\"\"\n",
        "Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. The term \"artificial intelligence\" had previously been used to describe machines that mimic and display \"human\" cognitive skills that are associated with the human mind, such as \"learning\" and \"problem-solving\". This definition has since been rejected by major AI researchers who now describe AI in terms of rationality and acting rationally, which does not limit how intelligence can be articulated.\n",
        "\n",
        "AI applications include advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), automated decision-making, and competing at the highest level in strategic game systems (such as chess and Go). As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n",
        "\"\"\"\n",
        "# Adjust repetitions if needed based on the output length check below.\n",
        "num_repetitions = 6 # Try increasing if input length is still too short\n",
        "long_context = (base_text + \"\\n\\n\") * num_repetitions\n",
        "\n",
        "question = \"Based *only* on the detailed text provided above about Artificial Intelligence, name three examples of AI applications mentioned.\"\n",
        "\n",
        "# --- Format the prompt using the chat template ---\n",
        "# Ensure tokenizer is available from previous cells\n",
        "try:\n",
        "    # Make sure 'tokenizer' variable exists\n",
        "    if 'tokenizer' not in locals():\n",
        "        raise NameError(\"'tokenizer' object not found. Please run Cell 4.\")\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an AI assistant. Answer questions based *only* on the provided text.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Context:\\n{long_context}\\n\\nQuestion: {question}\"}\n",
        "    ]\n",
        "    # This call returns the tensor directly in this case\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True, # Add the prompt for the assistant's turn\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Input prompt tokenized.\")\n",
        "except NameError as e:\n",
        "    print(f\"ERROR: {e}. Please ensure previous cells loading/defining objects have been run.\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Error during tokenization: {e}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# --- Check input length (Simpler version since 'inputs' is the tensor) ---\n",
        "print(\"\\n--- Input Tensor Check ---\")\n",
        "input_length = 0 # Default value\n",
        "if isinstance(inputs, torch.Tensor):\n",
        "    try:\n",
        "        print(f\"Shape of 'inputs' tensor: {inputs.shape}\")\n",
        "        # Get length from the last dimension (handles shape [N] or [1, N])\n",
        "        input_length = inputs.shape[-1]\n",
        "        print(f\"Determined input_length: {input_length}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing shape of 'inputs' tensor: {e}\")\n",
        "        # input_length remains 0\n",
        "else:\n",
        "    print(f\"Error: 'inputs' is not a tensor. Type: {type(inputs)}\")\n",
        "    # input_length remains 0\n",
        "\n",
        "# --- Length Check Logic (using determined input_length) ---\n",
        "# Ensure max_seq_length is available from Cell 3\n",
        "try:\n",
        "    # Make sure 'max_seq_length' variable exists from Cell 3\n",
        "    if 'max_seq_length' not in locals():\n",
        "         raise NameError(\"'max_seq_length' not defined. Please run Cell 3.\")\n",
        "    current_max_seq_length = max_seq_length\n",
        "except NameError as e:\n",
        "    print(f\"ERROR: {e}\")\n",
        "    raise\n",
        "\n",
        "if input_length == 0:\n",
        "    print(\"\\n*** Error determining input length from tokenizer output. Check tensor info above. Cannot proceed reliably. ***\")\n",
        "    # Skip generation if length couldn't be determined\n",
        "    generated_response_section = False\n",
        "else:\n",
        "    print(f\"\\nLength of tokenized input prompt: {input_length} tokens\")\n",
        "    if input_length <= 2048:\n",
        "        print(f\"*** WARNING: Input prompt ({input_length} tokens) is not significantly longer than the original 2048 limit. Consider increasing num_repetitions in this cell. ***\")\n",
        "    elif input_length > current_max_seq_length:\n",
        "        # Note: Actual truncation might happen inside model.generate, even if tokenizer doesn't truncate.\n",
        "        print(f\"*** WARNING: Input prompt ({input_length} tokens) exceeds the model's configured max_seq_length ({current_max_seq_length}). It will likely be truncated by the model during generation. ***\")\n",
        "    else:\n",
        "        print(f\"Input prompt length ({input_length} tokens) is within the extended limit ({current_max_seq_length} tokens).\")\n",
        "    generated_response_section = True # OK to proceed\n",
        "\n",
        "# Only proceed if input length was determined\n",
        "if generated_response_section:\n",
        "    # --- Set generation parameters ---\n",
        "    generation_params = {\n",
        "        \"max_new_tokens\": 100,\n",
        "        \"use_cache\": True,\n",
        "        \"do_sample\": False,\n",
        "        \"temperature\": 0.1,\n",
        "        \"top_p\": 0.9,\n",
        "        \"eos_token_id\": tokenizer.eos_token_id,\n",
        "        \"pad_token_id\": tokenizer.eos_token_id,\n",
        "    }\n",
        "\n",
        "    # --- Generate the response ---\n",
        "    print(\"\\nGenerating response based on long context...\")\n",
        "    response = \"Error during generation.\" # Default error message\n",
        "    try:\n",
        "        start_gen_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            # *** IMPORTANT: Pass the 'inputs' tensor directly to model.generate ***\n",
        "            outputs = model.generate(inputs, **generation_params)\n",
        "        end_gen_time = time.time()\n",
        "        print(f\"Generation took {end_gen_time - start_gen_time:.2f} seconds.\")\n",
        "\n",
        "        # Decode only the newly generated part\n",
        "        # Check if output is a tensor and has expected dimensions\n",
        "        if isinstance(outputs, torch.Tensor) and outputs.ndim > 0:\n",
        "             # Handle potential shape difference (e.g., output might be [1, seq_len])\n",
        "             output_seq_len = outputs.shape[-1]\n",
        "             input_seq_len = inputs.shape[-1] # Length determined earlier\n",
        "             if output_seq_len > input_seq_len:\n",
        "                 # Slice using the last dimension's shape\n",
        "                 response_tokens = outputs[0][input_seq_len:]\n",
        "                 response = tokenizer.decode(response_tokens, skip_special_tokens=True).strip()\n",
        "                 print(\"Response generated and decoded successfully.\")\n",
        "             else:\n",
        "                 print(\"Warning: Output sequence length is not greater than input length. No new tokens generated?\")\n",
        "                 response = \"[No new tokens generated]\"\n",
        "        else:\n",
        "             print(\"Warning: Unexpected output format from model.generate(). Decoding may fail.\")\n",
        "             print(\"Output type:\", type(outputs))\n",
        "             # Try decoding the whole output as fallback if it's a tensor\n",
        "             if isinstance(outputs, torch.Tensor) and outputs.ndim > 0:\n",
        "                  response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "             else:\n",
        "                  response = \"[Decoding failed due to unexpected output format]\"\n",
        "\n",
        "    except Exception as gen_err:\n",
        "        print(f\"Error during model generation or decoding: {gen_err}\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Print detailed traceback for generation errors\n",
        "\n",
        "\n",
        "    # --- Display results ---\n",
        "    print(f\"\\nQuestion: {question}\")\n",
        "    print(f\"\\nGenerated Response:\\n{response}\") # Check if it correctly extracts info\n",
        "\n",
        "# Clean up memory regardless of success\n",
        "if 'inputs' in locals(): del inputs\n",
        "if 'outputs' in locals(): del outputs\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Cleaned up memory.\")\n",
        "\n",
        "print(\"\\n=== Extended Context Inference Test Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwgUPk52RO4K",
        "outputId": "8efa8beb-a1ce-4b9c-f8a8-722219803a5a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Extended Context Inference Test...\n",
            "Model prepared for inference.\n",
            "Input prompt tokenized.\n",
            "\n",
            "--- Input Tensor Check ---\n",
            "Shape of 'inputs' tensor: torch.Size([1, 1977])\n",
            "Determined input_length: 1977\n",
            "\n",
            "Length of tokenized input prompt: 1977 tokens\n",
            "*** WARNING: Input prompt (1977 tokens) is not significantly longer than the original 2048 limit. Consider increasing num_repetitions in this cell. ***\n",
            "\n",
            "Generating response based on long context...\n",
            "Generation took 4.25 seconds.\n",
            "Response generated and decoded successfully.\n",
            "\n",
            "Question: Based *only* on the detailed text provided above about Artificial Intelligence, name three examples of AI applications mentioned.\n",
            "\n",
            "Generated Response:\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "Context: Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. The term \"artificial intelligence\" had previously been used to describe machines\n",
            "Cleaned up memory.\n",
            "\n",
            "=== Extended Context Inference Test Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question: Based only on the detailed text provided above about Artificial Intelligence, name three examples of AI applications mentioned.\n",
        "\n",
        "Generated Response:\n",
        "Context: Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. The term \"artificial intelligence\" had previously been used to describe machines."
      ],
      "metadata": {
        "id": "c1fmkrA3UwgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Datasets, Single Fine-tuning"
      ],
      "metadata": {
        "id": "XlvP3JJRU7fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TinyLlama\n",
        "model_name = \"unsloth/tinyllama-bnb-4bit\"\n",
        "max_seq_length = 1024 # Standard length sufficient for these tasks\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "output_directory = \"tinyllama_multi_dataset_adapters_run1\" # Specific name\n",
        "# Use small subsets & steps\n",
        "dolly_subset_size = 500 # Number of Dolly examples\n",
        "code_subset_size = 500 # Number of CodeAlpaca examples\n",
        "training_max_steps = 100 # Slightly more steps for mixed tasks\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Model: {model_name}\")\n",
        "print(f\"  Max Seq Length: {max_seq_length}\")\n",
        "print(f\"  Dolly Subset Size: {dolly_subset_size}\")\n",
        "print(f\"  Code Subset Size: {code_subset_size}\")\n",
        "print(f\"  Max Steps: {training_max_steps}\")\n",
        "print(\"=== Configuration Set ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUf_wUK1Trev",
        "outputId": "06eb257d-0e1f-4423-8df6-c198a97d37d8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration:\n",
            "  Model: unsloth/tinyllama-bnb-4bit\n",
            "  Max Seq Length: 1024\n",
            "  Dolly Subset Size: 500\n",
            "  Code Subset Size: 500\n",
            "  Max Steps: 100\n",
            "=== Configuration Set ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Loading Model and Tokenizer ---\")\n",
        "start_time = time.time()\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Model loaded in {end_time - start_time:.2f}s.\")\n",
        "\n",
        "# === Add Chat Template Fix ===\n",
        "# Manually set the ChatML template for TinyLlama tokenizer\n",
        "chatml_template = \"\"\"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{'<|im_start|>assistant\\n'}}{% endif %}\"\"\"\n",
        "if tokenizer.chat_template is None:\n",
        "     tokenizer.chat_template = chatml_template\n",
        "     print(\"Manually set tokenizer.chat_template to ChatML format.\")\n",
        "else:\n",
        "     print(\"Tokenizer chat template already set.\")\n",
        "# =============================\n",
        "\n",
        "# Ensure pad token is set (Unsloth usually does this, but good check)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(\"Set pad_token = eos_token\")\n",
        "\n",
        "print(\"=== Model and Tokenizer Loaded ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Q1KeRsVsC4",
        "outputId": "c0507f3c-65ea-4e0d-a5a9-2445cfd49e40"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Model and Tokenizer ---\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model loaded in 8.19s.\n",
            "Manually set tokenizer.chat_template to ChatML format.\n",
            "=== Model and Tokenizer Loaded ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Configuring LoRA ---\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Rank 16 might be good for mixed tasks\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0, # Use 0 for speed\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True,\n",
        "    random_state = 3407,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        ")\n",
        "print(\"LoRA configured:\")\n",
        "print(model.print_trainable_parameters())\n",
        "print(\"=== LoRA Configured ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azs__R-MVxCw",
        "outputId": "d5e5ffae-88c9-4ce3-b331-e2a834ce1e8a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Configuring LoRA ---\n",
            "LoRA configured:\n",
            "trainable params: 12,615,680 || all params: 1,112,664,064 || trainable%: 1.1338\n",
            "None\n",
            "=== LoRA Configured ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Dolly Dataset ---\n",
        "print(\"Loading Databricks Dolly dataset...\")\n",
        "try:\n",
        "    dolly_dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "    dolly_dataset = dolly_dataset.shuffle(seed=42).select(range(dolly_subset_size))\n",
        "    print(f\"Loaded {len(dolly_dataset)} Dolly examples.\")\n",
        "    print(\"Dolly features:\", dolly_dataset.features)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Dolly dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- Load CodeAlpaca Dataset ---\n",
        "# Using HuggingFaceH4 version as it worked previously\n",
        "print(\"\\nLoading CodeAlpaca dataset (HuggingFaceH4)...\")\n",
        "try:\n",
        "    code_dataset = load_dataset(\"HuggingFaceH4/CodeAlpaca_20K\", split=\"train\")\n",
        "    code_dataset = code_dataset.shuffle(seed=42).select(range(code_subset_size))\n",
        "    print(f\"Loaded {len(code_dataset)} CodeAlpaca examples.\")\n",
        "    print(\"CodeAlpaca features:\", code_dataset.features)\n",
        "    # Expected features: prompt, input/output or completion... verify these!\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CodeAlpaca dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\n=== All Raw Datasets Loaded ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "229c5403a59542e9b754cba8cb181325",
            "d2ca85de945a49ab8db4e172d4d892df",
            "a4d3c010e72144019339b41ce216ee2b",
            "8435f82def2647e49d047bff3fc99865",
            "874661f214c34f5485f30d59f885cb0a",
            "3082aaf565b3498a8c514084c36c50d3",
            "b9a42c0aa0c6478a9a2800120c1be15e",
            "e1701a038a2544feb735a834e022f74c",
            "1d62e2240fe540198ef4c71080cda0da",
            "edbf074eafa342b086aeb7656e3fe404",
            "5bdadebee97e48e99aedd8550aa4be2b",
            "686df5db4951455f83a31f64a0983f2d",
            "8baa4dc1ff4a419ebb2b74864bc43c96",
            "9917df6ca95946c087837c8d282fc735",
            "ca621602c3524d668c89635385d3b82a",
            "120a0219981f47a7a08d1c8a03b7091d",
            "500f54026a564ee4b620b2c90e419ac8",
            "7c5412d3858b4ad6b49c6709787d64f8",
            "9f51796a196f40ccaee8a8d20dd87b25",
            "c4617716d7f64abbaffafecef0c4d0d5",
            "b9e30c0adae04955848171a8e4d4a2da",
            "e844e987322d458a8c03eafd2700a83c",
            "e5825fe897284d638c3f7ff69d43ccf2",
            "5eb37ba6adff4499b32eb3a377e07f96",
            "8faedce92fcd406db7bd76bc521ace44",
            "a315a3173c9d4faa93b1c088b974b8f0",
            "6c5bb05001ed4d30835a763d250883f6",
            "567cd7a0eeb14dc39997fed44ab9b89f",
            "caca41ae7bd749f3bdb84c3e671ec813",
            "95e0cafa9a5a49648d4e1ab62dabd739",
            "e582cdea70ab4425bee50eff65eb0ed6",
            "1bfba5d4cf454d00875f2c33addc5cb5",
            "5bbe244940ae4802a78a79c3dcba97f8",
            "632e881723584c9d8c701f0c36ff3da5",
            "d5b3676c07b44c158c3d6ce8f726b163",
            "44536c2436f84d17976de04560f63c00",
            "a5c2b206331d4d37b86107cc9249ec27",
            "945ae950267a42ff947e19e1de74bffe",
            "bfe880923f404305b8a75fd3afb0ee01",
            "4f87ac6c92f1450391a270cdf0d09fae",
            "71867c73e9024d7c9f11b532ea4cd8ee",
            "8dbee8b3764d4958ac3c9b908f2d6260",
            "ff47a1b76b4742f199d830f59e4dd6ba",
            "0e33d4bba98f49598fbf92e01f87348a",
            "e0e193354c814f7f884f3aa380083456",
            "1111cd7176a541c38ad3680c264f7c24",
            "a17c10e63e4a41b1a935249cd8596488",
            "d35abf406f84428bbd3fc2773bd47812",
            "2b5c0cf7cd8a47edbd3cd3cadde619d5",
            "35ac4bb0852740a18d8ddfe1aec80cc8",
            "220396acf2a949f886cbfd4ed54d20fb",
            "b33595b17f7249049c987df1f42acf22",
            "68782b8914cd4bb480aea901267f613e",
            "28d1d6c09cf848d5b20fb997fc6ef569",
            "68f5a5b3c270492eb0395b601e853817",
            "a1ebf4261af34400b8d8bea6bf941be0",
            "a01a56e0b98d4a22828bae59a2862e16",
            "3e1eabf3246743c3b7875c5eb24f2153",
            "76ed5d5893c4472aa2cb32c1cb85ab53",
            "f1300d68e995411b80352bf084c47886",
            "867e2d1f876a4042820e740e83eb7d03",
            "ddfbfd1fe5ff452b812c3ca071e907b3",
            "1341ae5bdc6c45849f40e8f444dfa4e1",
            "980a75390fef473b9abc5068afc8063f",
            "affb3dcce70e4182be0fda5a5f181f19",
            "188ade3e5f38400aaffa5881bba6eada"
          ]
        },
        "id": "BVGA4_6CVzk9",
        "outputId": "1dc99def-9ac0-433a-8736-8dd5247b3e29"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Databricks Dolly dataset...\n",
            "Loaded 500 Dolly examples.\n",
            "Dolly features: {'instruction': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'response': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None)}\n",
            "\n",
            "Loading CodeAlpaca dataset (HuggingFaceH4)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/195 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "229c5403a59542e9b754cba8cb181325"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dataset_infos.json:   0%|          | 0.00/756 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "686df5db4951455f83a31f64a0983f2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/3.01M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5825fe897284d638c3f7ff69d43ccf2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/336k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "632e881723584c9d8c701f0c36ff3da5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/18019 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0e193354c814f7f884f3aa380083456"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2003 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1ebf4261af34400b8d8bea6bf941be0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 500 CodeAlpaca examples.\n",
            "CodeAlpaca features: {'prompt': Value(dtype='string', id=None), 'completion': Value(dtype='string', id=None)}\n",
            "\n",
            "=== All Raw Datasets Loaded ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Defining Formatting Functions ---\")\n",
        "\n",
        "# *** CRITICAL: Both functions must output the *SAME* final column name ('text') ***\n",
        "# *** and use the *SAME* chat template structure ***\n",
        "\n",
        "# --- Formatting function for Dolly ---\n",
        "def format_dolly_for_multitask(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    contexts = examples[\"context\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for instruction, context, response in zip(instructions, contexts, responses):\n",
        "        user_content = instruction\n",
        "        if context and context.strip():\n",
        "            user_content = f\"Context: {context.strip()}\\n\\nInstruction: {instruction.strip()}\"\n",
        "        # Use the ChatML template structure set on the tokenizer\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, # General system prompt\n",
        "            {\"role\": \"user\", \"content\": user_content},\n",
        "            {\"role\": \"assistant\", \"content\": response}\n",
        "        ]\n",
        "        try:\n",
        "            # add_generation_prompt=False because we provide the full conversation turn\n",
        "            formatted = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "            texts.append(formatted)\n",
        "        except Exception as e:\n",
        "            print(f\"Error formatting Dolly example: {e}\")\n",
        "            texts.append(\"\") # Append empty on error\n",
        "    # *** Output column must be named 'text' ***\n",
        "    return {\"text\": texts}\n",
        "print(\"Dolly formatting function defined.\")\n",
        "\n",
        "# --- Formatting function for CodeAlpaca ---\n",
        "# *** IMPORTANT: VERIFY these column names from Cell 6 output for CodeAlpaca_20K ***\n",
        "# *** IMPORTANT: VERIFY these column names from Cell 6 output for CodeAlpaca_20K ***\n",
        "code_instruction_col = \"prompt\"      # KEEP AS IS - Matches dataset\n",
        "code_input_col = None                # CHANGE - No separate 'input' column exists\n",
        "code_output_col = \"completion\"       # CHANGE - Matches dataset output column'\n",
        "\n",
        "# Check if columns exist before defining function\n",
        "missing_cols = []\n",
        "if code_instruction_col not in code_dataset.features: missing_cols.append(code_instruction_col)\n",
        "# Check input only if it's expected (not None)\n",
        "if code_input_col is not None and code_input_col not in code_dataset.features: missing_cols.append(code_input_col)\n",
        "if code_output_col not in code_dataset.features: missing_cols.append(code_output_col)\n",
        "\n",
        "if missing_cols:\n",
        "    print(f\"\\n*** FATAL ERROR: The following required column(s) for CodeAlpaca are missing: {missing_cols} ***\")\n",
        "    print(f\"    Please check the actual features in Cell 6 output ({code_dataset.features}) and update the variables 'code_instruction_col', 'code_input_col', 'code_output_col' in this cell.\")\n",
        "    raise KeyError(f\"Missing required CodeAlpaca columns: {missing_cols}\")\n",
        "else:\n",
        "    print(f\"Using CodeAlpaca columns: instruction='{code_instruction_col}', input='{code_input_col}', output='{code_output_col}'\")\n",
        "\n",
        "def format_codealpaca_for_multitask(examples):\n",
        "    instructions = examples[code_instruction_col]\n",
        "    # Handle potential absence or presence of input column correctly\n",
        "    inputs = examples[code_input_col] if code_input_col in examples else [None] * len(instructions)\n",
        "    outputs = examples[code_output_col]\n",
        "    texts = []\n",
        "    for instruction, input_text, output in zip(instructions, inputs, outputs):\n",
        "        user_content = instruction\n",
        "        # Check if input_text exists and is not just whitespace\n",
        "        if input_text is not None and str(input_text).strip():\n",
        "             user_content += \"\\n\" + str(input_text) # Append input if it exists\n",
        "\n",
        "        # Use the same ChatML template structure\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, # Consistent system prompt\n",
        "            {\"role\": \"user\", \"content\": user_content.strip()},\n",
        "            {\"role\": \"assistant\", \"content\": output}\n",
        "        ]\n",
        "        try:\n",
        "            formatted = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "            texts.append(formatted)\n",
        "        except Exception as e:\n",
        "            print(f\"Error formatting CodeAlpaca example: {e}\")\n",
        "            texts.append(\"\")\n",
        "     # *** Output column must be named 'text' ***\n",
        "    return {\"text\": texts}\n",
        "print(\"CodeAlpaca formatting function defined.\")\n",
        "\n",
        "print(\"=== Formatting Functions Defined ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6BjLKtbV4BF",
        "outputId": "8de5aaf8-986f-48a1-cc9d-17f286faeaf8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining Formatting Functions ---\n",
            "Dolly formatting function defined.\n",
            "Using CodeAlpaca columns: instruction='prompt', input='None', output='completion'\n",
            "CodeAlpaca formatting function defined.\n",
            "=== Formatting Functions Defined ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ... other imports ...\n",
        "from datasets import load_dataset, concatenate_datasets # <<< Import concatenate_datasets\n",
        "# ... rest of imports ...\n",
        "\n",
        "print(\"--- Applying Formatting and Combining Datasets ---\")\n",
        "\n",
        "# Apply formatting to Dolly\n",
        "print(\"Applying formatting to Dolly dataset...\")\n",
        "start_map_time = time.time()\n",
        "formatted_dolly = dolly_dataset.map(\n",
        "    format_dolly_for_multitask,\n",
        "    batched=True,\n",
        "    num_proc=2, # Use multiprocessing\n",
        "    remove_columns=list(dolly_dataset.features) # Keep only 'text'\n",
        ")\n",
        "end_map_time = time.time()\n",
        "print(f\"Dolly formatted in {end_map_time - start_map_time:.2f}s. Features: {formatted_dolly.features}\")\n",
        "\n",
        "# Apply formatting to CodeAlpaca\n",
        "print(\"\\nApplying formatting to CodeAlpaca dataset...\")\n",
        "start_map_time = time.time()\n",
        "formatted_code = code_dataset.map(\n",
        "    format_codealpaca_for_multitask,\n",
        "    batched=True,\n",
        "    num_proc=2, # Use multiprocessing\n",
        "    remove_columns=list(code_dataset.features) # Keep only 'text'\n",
        ")\n",
        "end_map_time = time.time()\n",
        "print(f\"CodeAlpaca formatted in {end_map_time - start_map_time:.2f}s. Features: {formatted_code.features}\")\n",
        "\n",
        "\n",
        "# --- Concatenate the datasets ---\n",
        "print(\"\\nConcatenating datasets...\")\n",
        "# Safety check for the 'text' column\n",
        "if 'text' not in formatted_dolly.features or 'text' not in formatted_code.features:\n",
        "     raise ValueError(\"One or both datasets are missing the required 'text' column after formatting. Check formatting functions.\")\n",
        "\n",
        "combined_dataset = concatenate_datasets([formatted_dolly, formatted_code])\n",
        "print(f\"Combined dataset size: {len(combined_dataset)}\")\n",
        "\n",
        "# --- Shuffle the combined dataset ---\n",
        "# Shuffling is crucial so the model sees a mix of tasks during training\n",
        "combined_dataset = combined_dataset.shuffle(seed=42)\n",
        "print(\"Combined dataset shuffled.\")\n",
        "\n",
        "# Verify combined dataset structure and content\n",
        "print(\"\\nCombined dataset features:\", combined_dataset.features)\n",
        "if len(combined_dataset) > 0:\n",
        "    print(\"\\nExample entry 1 (first 500 chars):\")\n",
        "    print(combined_dataset[0]['text'][:500])\n",
        "    print(\"\\nExample entry 2 (middle element, first 500 chars):\")\n",
        "    print(combined_dataset[len(combined_dataset)//2]['text'][:500])\n",
        "    print(\"\\nExample entry 3 (last element, first 500 chars):\")\n",
        "    print(combined_dataset[-1]['text'][:500]) # Check if examples from both datasets appear mixed\n",
        "else:\n",
        "    print(\"\\nWarning: Combined dataset is empty.\")\n",
        "\n",
        "print(\"\\n=== Datasets Combined and Shuffled ===\")\n",
        "# Clean up intermediate datasets to save memory\n",
        "del formatted_dolly, formatted_code, dolly_dataset, code_dataset\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpvIF7iVWIV5",
        "outputId": "ec9b48da-55e3-4ab1-d059-9448af5d41b0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Applying Formatting and Combining Datasets ---\n",
            "Applying formatting to Dolly dataset...\n",
            "Dolly formatted in 0.06s. Features: {'text': Value(dtype='string', id=None)}\n",
            "\n",
            "Applying formatting to CodeAlpaca dataset...\n",
            "CodeAlpaca formatted in 0.05s. Features: {'text': Value(dtype='string', id=None)}\n",
            "\n",
            "Concatenating datasets...\n",
            "Combined dataset size: 1000\n",
            "Combined dataset shuffled.\n",
            "\n",
            "Combined dataset features: {'text': Value(dtype='string', id=None)}\n",
            "\n",
            "Example entry 1 (first 500 chars):\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Generate a valid regex pattern that finds instances of the word “unicorn” appearing at the end of a sentence.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\\bunicorn\\b\\.$<|im_end|>\n",
            "\n",
            "\n",
            "Example entry 2 (middle element, first 500 chars):\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Rewrite the following JavaScript code in the Java language.\n",
            "const numList = [1, 2, 3, 4];\n",
            "\n",
            "numList.map((num) => {\n",
            "  return num * 2;\n",
            "});<|im_end|>\n",
            "<|im_start|>assistant\n",
            "int[] numList = {1, 2, 3, 4};\n",
            "\n",
            "for (int i = 0; i < numList.length; i++) {\n",
            "  numList[i] = numList[i] * 2;\n",
            "}<|im_end|>\n",
            "\n",
            "\n",
            "Example entry 3 (last element, first 500 chars):\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Generate a python code that takes a list of integers, prints out an array that is all True if the values are in the input list and all False otherwise.\n",
            "list_of_numbers = [5, 7, 10, 2]<|im_end|>\n",
            "<|im_start|>assistant\n",
            "def boolean_search(list_of_numbers):\n",
            "    result_array = []\n",
            "    for elem in list_of_numbers:\n",
            "        result_array.append(elem in list_of_numbers)\n",
            "    return result_array<|im_end|>\n",
            "\n",
            "\n",
            "=== Datasets Combined and Shuffled ===\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Configuring Trainer ---\")\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=combined_dataset, # <<< Use the combined dataset\n",
        "    dataset_text_field=\"text\",      # The common output column from formatting functions\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=True, # Packing is generally good for mixed datasets to utilize context window\n",
        "\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2, # Adjust based on memory\n",
        "        gradient_accumulation_steps=8, # Effective batch size 16\n",
        "        warmup_steps=10,\n",
        "        max_steps=training_max_steps, # Train for fixed steps\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=output_directory, # Directory for checkpoints\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=50, # Save midway through the short training\n",
        "        report_to=\"tensorboard\", # Optional logging\n",
        "    ),\n",
        ")\n",
        "print(\"Trainer configured for multi-dataset fine-tuning.\")\n",
        "print(\"=== Trainer Configured ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "1ed4565a420a446a9a750cede1e620be",
            "16c45728653e42db92b9c4debedff486",
            "914d07dac8f744388ef367626a37c881",
            "d4beadce3d454fdf9926fd27f51392d0",
            "4a012f9dcabe4717b0a78b9e6f1ad6b2",
            "5e1352785cb84d0ca9489dbf92c3b93e",
            "adeb80c9e1494a919341c505770b2ab8",
            "7490f4d201f94aef89d6e77dd3cf4928",
            "65f8239a11984069aa8afb86f16f8bf2",
            "c7317739fc8a4350ae7a8be23cf09038",
            "0e4dbe3b78b34b0ea01bdffc5fea6073"
          ]
        },
        "id": "fz5fzUq8Wimm",
        "outputId": "db7fe34b-bfb1-4975-b5b4-b32d963e8866"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Configuring Trainer ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ed4565a420a446a9a750cede1e620be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer configured for multi-dataset fine-tuning.\n",
            "=== Trainer Configured ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"--- Starting Multi-Dataset Training (max_steps={training_max_steps}) ---\")\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Cleared CUDA cache.\")\n",
        "\n",
        "start_train_time = time.time()\n",
        "trainer.train()\n",
        "end_train_time = time.time()\n",
        "\n",
        "print(f\"Training finished in {(end_train_time - start_train_time)/60:.2f} minutes.\")\n",
        "# Observe loss, it might fluctuate more than single-task training\n",
        "print(\"=== Training Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "WOj84e7MWZyb",
        "outputId": "f9234d5e-1ed2-4e73-931a-78ee3116d8c9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Multi-Dataset Training (max_steps=100) ---\n",
            "Cleared CUDA cache.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 215 | Num Epochs = 8 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 12,615,680/4,000,000,000 (0.32% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 05:30, Epoch 7/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.673200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.346400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.261600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.186200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.149400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.109800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.126800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.095800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.042300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.067300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished in 5.60 minutes.\n",
            "=== Training Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_adapter_dir = f\"{output_directory}/final_adapters\"\n",
        "print(f\"\\n--- Saving final LoRA adapters to: {final_adapter_dir} ---\")\n",
        "trainer.model.save_pretrained(final_adapter_dir) # Save the PEFT model\n",
        "tokenizer.save_pretrained(final_adapter_dir) # Save tokenizer too\n",
        "print(f\"Adapters and tokenizer saved to {final_adapter_dir}.\")\n",
        "# Verify files\n",
        "!ls -lh {final_adapter_dir}\n",
        "print(\"=== Adapters Saved ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUrkKzaVWmU5",
        "outputId": "6feba822-460a-4fc7-feb2-53f7b5ac5917"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Saving final LoRA adapters to: tinyllama_multi_dataset_adapters_run1/final_adapters ---\n",
            "Adapters and tokenizer saved to tinyllama_multi_dataset_adapters_run1/final_adapters.\n",
            "total 53M\n",
            "-rw-r--r-- 1 root root  797 Apr  8 07:48 adapter_config.json\n",
            "-rw-r--r-- 1 root root  49M Apr  8 07:48 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root 5.0K Apr  8 07:48 README.md\n",
            "-rw-r--r-- 1 root root  552 Apr  8 07:48 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 1.2K Apr  8 07:48 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root 3.5M Apr  8 07:48 tokenizer.json\n",
            "-rw-r--r-- 1 root root 489K Apr  8 07:48 tokenizer.model\n",
            "=== Adapters Saved ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Running Multi-Dataset Inference Test ---\")\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Prepare model for inference\n",
        "# Assuming 'trainer.model' holds the fine-tuned model\n",
        "final_model = trainer.model\n",
        "try:\n",
        "    FastLanguageModel.for_inference(final_model)\n",
        "    final_model.eval()\n",
        "    print(\"Model prepared for inference.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error preparing model for inference: {e}\")\n",
        "    # If error, may need to reload:\n",
        "    # print(\"Attempting to reload model and adapters...\")\n",
        "    # from peft import PeftModel\n",
        "    # model, tokenizer = FastLanguageModel.from_pretrained(...) # Reload base model + tokenizer from Cell 4 config\n",
        "    # # Add template fix again if reloading tokenizer\n",
        "    # final_model = PeftModel.from_pretrained(model, final_adapter_dir) # Load adapters\n",
        "    # FastLanguageModel.for_inference(final_model)\n",
        "    # final_model.eval()\n",
        "    # print(\"Model reloaded and prepared.\")\n",
        "\n",
        "\n",
        "# --- Test Prompt 1: Conversational (Dolly style) ---\n",
        "print(\"\\n--- Test 1: Conversational ---\")\n",
        "test_chat_prompt = \"Explain the concept of machine learning in simple terms.\"\n",
        "messages_chat = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": test_chat_prompt}\n",
        "]\n",
        "inputs_chat = tokenizer.apply_chat_template(messages_chat, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Handle tensor direct return if necessary\n",
        "if not isinstance(inputs_chat, torch.Tensor): inputs_chat = inputs_chat.input_ids\n",
        "\n",
        "generation_params_chat = {\n",
        "    \"max_new_tokens\": 150, \"use_cache\": True, \"do_sample\": True,\n",
        "    \"temperature\": 0.7, \"top_p\": 0.9, \"eos_token_id\": tokenizer.eos_token_id,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "}\n",
        "\n",
        "print(f\"User: {test_chat_prompt}\")\n",
        "response_chat = \"[Chat Generation Failed]\"\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        outputs_chat = final_model.generate(inputs_chat, **generation_params_chat)\n",
        "    # Decode response\n",
        "    output_seq_len = outputs_chat.shape[-1]\n",
        "    input_seq_len = inputs_chat.shape[-1]\n",
        "    if output_seq_len > input_seq_len:\n",
        "        response_tokens = outputs_chat[0][input_seq_len:]\n",
        "        response_chat = tokenizer.decode(response_tokens, skip_special_tokens=True).strip()\n",
        "    else: response_chat = \"[No new tokens]\"\n",
        "except Exception as e: print(f\"Chat generation error: {e}\")\n",
        "print(f\"Assistant: {response_chat}\")\n",
        "\n",
        "\n",
        "# --- Test Prompt 2: Coding (CodeAlpaca style) ---\n",
        "print(\"\\n--- Test 2: Coding ---\")\n",
        "test_code_prompt = \"Write a short Python function to reverse a string.\"\n",
        "messages_code = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": test_code_prompt}\n",
        "]\n",
        "inputs_code = tokenizer.apply_chat_template(messages_code, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Handle tensor direct return if necessary\n",
        "if not isinstance(inputs_code, torch.Tensor): inputs_code = inputs_code.input_ids\n",
        "\n",
        "\n",
        "generation_params_code = {\n",
        "    \"max_new_tokens\": 100, \"use_cache\": True, \"do_sample\": True, # Sample for code too\n",
        "    \"temperature\": 0.5, \"top_p\": 0.9, \"eos_token_id\": tokenizer.eos_token_id,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "}\n",
        "\n",
        "print(f\"User: {test_code_prompt}\")\n",
        "response_code = \"[Code Generation Failed]\"\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        outputs_code = final_model.generate(inputs_code, **generation_params_code)\n",
        "    # Decode response\n",
        "    output_seq_len = outputs_code.shape[-1]\n",
        "    input_seq_len = inputs_code.shape[-1]\n",
        "    if output_seq_len > input_seq_len:\n",
        "        response_tokens = outputs_code[0][input_seq_len:]\n",
        "        response_code = tokenizer.decode(response_tokens, skip_special_tokens=True).strip()\n",
        "    else: response_code = \"[No new tokens]\"\n",
        "except Exception as e: print(f\"Code generation error: {e}\")\n",
        "print(f\"Assistant:\\n{response_code}\") # Add newline for code formatting\n",
        "\n",
        "# Clean up\n",
        "del final_model\n",
        "if 'inputs_chat' in locals(): del inputs_chat\n",
        "if 'outputs_chat' in locals(): del outputs_chat\n",
        "if 'inputs_code' in locals(): del inputs_code\n",
        "if 'outputs_code' in locals(): del outputs_code\n",
        "if 'combined_dataset' in locals(): del combined_dataset # Free dataset memory\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"\\nCleaned up memory.\")\n",
        "\n",
        "print(\"\\n=== Multi-Dataset Inference Test Complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0U7Hm6VWple",
        "outputId": "2e4eabba-d890-4698-bf2b-054d9ba8eb1e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Multi-Dataset Inference Test ---\n",
            "Model prepared for inference.\n",
            "\n",
            "--- Test 1: Conversational ---\n",
            "User: Explain the concept of machine learning in simple terms.\n",
            "Assistant: Machine learning is the field that deals with creating algorithms and programs to solve problems. It uses machine learning algorithms to make decisions and predictions. Machine learning algorithms are used to train a model to make predictions based on past data. Machine learning algorithms can be used for classification, regression, and clustering.<|im_end|>\n",
            "\n",
            "--- Test 2: Coding ---\n",
            "User: Write a short Python function to reverse a string.\n",
            "Assistant:\n",
            "def reverse(s):\n",
            "    return s[::-1]<|im_end|>\n",
            "\n",
            "Cleaned up memory.\n",
            "\n",
            "=== Multi-Dataset Inference Test Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00SZDnsfX6W3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}